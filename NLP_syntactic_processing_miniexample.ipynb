{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgromann/ProgrammingForTranslators/blob/master/NLP_syntactic_processing_miniexample.ipynb\" target=\"_parent\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcnUc0sL9433",
        "colab_type": "text"
      },
      "source": [
        "##Programmieren für ÜbersetzerInnen\n",
        "\n",
        "Dieses Notebook bietet einige interaktive Programmierübungen für Ihre ersten Schritte in der Welt des Programmierens. Diese Umbegung wurde eigens für diesen Workshop angelegt. \n",
        "\n",
        "Wenn Sie den nachfolgenden Code auf Ihrem eigenen Windows-Computer zuhause ausführen möchten, folgen Sie bitte den Anweisungen in der Datei \"Windows-Programmierumgebung\". \n",
        "\n",
        "Selbstverständlich können Sie auch von zuhause in dieser Umgebung weiter üben - Sie können diese Umgebung in jedem Browser starten. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOvb9Vy1-NYU",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization\n",
        "Next, we will import the SpaCy library to python and give it a first statement to tokenize. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a440aXyf-XdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(\"Welcome to the NLP pipeline in SpaCy!\")\n",
        "for token in doc:\n",
        "    print('\"' + token.text + '\"', token.idx)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cktd3je2-rZ5",
        "colab_type": "text"
      },
      "source": [
        "# Sentence detection\n",
        "\n",
        "We can also detect individual sentences in a longer text. The good thing about NLTK is that it comes with a number of preprocessed and cleaned corpora, such as the Brown corpus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCr0HhF0-qo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "#only for the first time\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg as gutenberg\n",
        "\n",
        "gutenberg.fileids()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSx4iqinAR86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "excerpt = gutenberg.raw('austen-sense.txt')[0:1000]\n",
        "print(excerpt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJE6QAx7Q7BT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsZHxK2kB7fx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_text = nlp(excerpt)\n",
        "for sent in processed_text.sents: \n",
        "  print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_NUxbObDqPO",
        "colab_type": "text"
      },
      "source": [
        "# POS Tagging\n",
        "\n",
        "Part-of-speech tagging is the process of identifying word classes for each individual word. \n",
        "\n",
        "For instance \"NN\" refers to a noun singular, \"CC\" denotes a coordination, etc. The whole collection of highly conventional tags can be found in the [Penn Treebank listing](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vn3jvSEDr4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print([(token.text, token.tag_) for token in processed_text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcr9FOK-EXN1",
        "colab_type": "text"
      },
      "source": [
        "Which process is the following? Which elements of the text are being extracted?\n",
        "\n",
        "GPE, for instance, denotes geopolitical entity, FAC refers to \"Buildings, airports, highways, bridges, etc.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYORqBbeEWcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ent in processed_text.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02se4DGqFiJi",
        "colab_type": "text"
      },
      "source": [
        "And its visual representation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ND9kb0FFcIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy import displacy\n",
        "displacy.render(processed_text, style='ent', jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWNSjhIdFpst",
        "colab_type": "text"
      },
      "source": [
        "# Dependency Parsing \n",
        "\n",
        "What can we learn from dependency parsing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v3gZMOpFtwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "displacy.render(processed_text[13:24], style='dep', jupyter=True, options={'distance': 90})"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
