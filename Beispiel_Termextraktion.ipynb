{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beispiel_Termextraktion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPe9IF/EWF0jIvy9j0DMeLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgromann/ProgrammingForTranslators/blob/master/Beispiel_Termextraktion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV_GBl7azbZ_",
        "colab_type": "text"
      },
      "source": [
        "# Programmieren für ÜbersetzerInnen - Beispiel Termextraktion\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLczbpNuBE3h",
        "colab_type": "text"
      },
      "source": [
        "Als erstes Beispiel nach der Einführung schreiben wir ein simples Programm zur Termextraktion unter Verwendung des statistischen Maßes TF-IDF. TF-IDF steht für Termhäufigkeit (TF) und Inverse Dokumentenhäufigkeit (IDF) und ist ein Maß zur Berechnung der Gewichtung eines Wortes/einer Phrase in einem Dokument -  damit können fachsprachliche Benennungen extrahiert werden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOhvFdsMzZfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unser Beispielkorpus\n",
        "document1 = \"Sendung von Gold in einem Container.\" \n",
        "document2= \"Lieferung von Silber in einem silbernen LKW angekommen.\" \n",
        "document3 = \"Sendung von Gold in einem LKW angekommen.\"\n",
        "corpus = [document1, document2, document3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6QxQPHJMbZF",
        "colab_type": "text"
      },
      "source": [
        "Um spaCy auch in diesem Notebook verwenden zu können, müssen wir es wieder laden und die deutschen Pakete laden - installiert haben wir spacy zentral für das gesamte System:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj8t9F0OMjGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy \n",
        "\n",
        "nlp = spacy.load(\"de_core_news_sm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNZMU0S8BhuW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Wir verwenden hier die Vorverarbeitungsmethode aus dem letzten Beispiel. Da diese in einem anderen Notebook steht, müssen wir Sie hier noch einmal wiedergeben: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ej-1UNjTxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(sentence):\n",
        "  sentence = sentence.lower() \n",
        "  # Wir fügen auch gleich ein paar weitere POS-Tags für Konjunktionen, etc. hinzu \n",
        "  pos_to_be_removed =['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE']\n",
        "  text_out = []\n",
        "  # Tokenisiert und weitere Vorverarbeitung\n",
        "  doc= nlp(text)\n",
        "  for token in doc:\n",
        "    # POS-Tags überprüft und nur jene die nicht in \"pos_to_be_removed\" zu finden sind berücksichtigen\n",
        "    if token.pos_ not in pos_to_be_removed :\n",
        "      #Lemmatisierung\n",
        "      lemma = token.lemma_\n",
        "      text_out.append(lemma)\n",
        "    return text_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5EHpO-LnYtQ",
        "colab_type": "text"
      },
      "source": [
        "**Aufgabe** \\\\\n",
        "Rufen Sie die oben definierte Methode preprocessing für jeden Satz des Korpus `corpus` auf und speichern Sie das Ergebnis in eine neue Liste `reprocessed`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-i3QsBhnku_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# neue Liste preprocessed \n",
        "preprocessed = []\n",
        "\n",
        "# jedes Dokument (Satz) in der Variable corpus durch die Metehodee preprocessing bearbeiten\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl5zc3egNtzO",
        "colab_type": "text"
      },
      "source": [
        "# TF-IDF\n",
        "Anstelle der manuellen Berechnung der TF-IDF Werte, verwenden wir eine bereitgestellte Library für maschinelles Lernen. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD1qwThnOL4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "word_index = vectorizer.vocabulary_\n",
        "\n",
        "print(\"Wortindex: \", word_index)\n",
        "print(\"TF-IDF Matrix: \")\n",
        "print(\"(Dokumentennummer, Termindex) TF-IDF Weight\")\n",
        "print(tfidf_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIjmyj50S68s",
        "colab_type": "text"
      },
      "source": [
        "Der nachstehende Code extrahiert die `n` wichtigsten Terme aus unserem Mini-Korpus. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1nKhThCTU_M",
        "colab_type": "text"
      },
      "source": [
        "**Frage** \\\\\n",
        "Würden Sie sagen, dass diese Auswahl für diesen Mini-Korpus Sinn macht? Stellen diese Worte tatsächlich wichtige semantische Bestandteile unseres Korpus dar?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWIcweEtQy_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "feature_array = np.array(vectorizer.get_feature_names())\n",
        "tfidf_sorting = np.argsort(tfidf_matrix.toarray()).flatten()[::-1]\n",
        "\n",
        "n = 3\n",
        "top_n = feature_array[tfidf_sorting][:n]\n",
        "print(top_n)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}