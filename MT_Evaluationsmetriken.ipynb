{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT_Evaluationsmetriken.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcZCVnEvSQ3wBy3jdKYBGp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgromann/ProgrammingForTranslators/blob/master/MT_Evaluationsmetriken.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluationsmetriken für maschinelle Übersetzung\n",
        "\n",
        "Dieses Google Collaboratory (Colab) Notebook präsentiert eine einfach und rasche Umsetzung von gängigen Evaluationsmetriken. Dazu muss nichts installiert werden und die Berechnung erfolgt direkt im Browser. "
      ],
      "metadata": {
        "id": "4aP9JhHyk9hE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Google Colab gibt es Textsegmente wie dieses in weiß und graue Code-Segmente. Wenn Sie in ein graues Segment klicken, erscheint links oben ein Schaltfläche, die es erlaubt das jeweilige Segment auszuführen. Die Ausgabe des Segmentes sehen Sie dann darunter."
      ],
      "metadata": {
        "id": "NqDYn3EplVva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade nltk"
      ],
      "metadata": {
        "id": "cnyVjfR3pi8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "2muoaMeJqS7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets # Metriken und Datensätze für Transformers \n",
        "!pip install -q sacrebleu # Verbesserte Variante von BLEU; Abhängigkeit von datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xvd7WxCm-ti",
        "outputId": "948b91f6-ade4-45c0-c2c6-18d428d6f6ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▋                            | 10 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 20 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 30 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 40 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 51 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 61 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 71 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 81 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 90 kB 6.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Edit distance"
      ],
      "metadata": {
        "id": "8Z_vHH4plwHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "\n",
        "reference = \"This is a test\"\n",
        "candidate = \"This is not a test\"\n",
        "\n",
        "edit_distance = nltk.edit_distance(reference, candidate, transpositions=False)\n",
        "print(edit_distance)"
      ],
      "metadata": {
        "id": "wQgO_L8GmhZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Metriken"
      ],
      "metadata": {
        "id": "DIvKYzxzlrUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluationsmetriken importieren und die Auswahl ausgeben\n",
        "from datasets import list_metrics\n",
        "\n",
        "metrics_list = list_metrics()\n",
        "print((metrics_list))"
      ],
      "metadata": {
        "id": "Tv8s5wPrjOIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SacreBLEU"
      ],
      "metadata": {
        "id": "vRh7pRtAtW1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "# Evaluationsmetrik laden\n",
        "metric = load_metric('sacrebleu')\n",
        "\n",
        "# Die nachstehende Zeile (wenn ohne \"#\" ausgeführt, beschreibt die Software-Bibliothek)\n",
        "print(metric)\n",
        "\n",
        "reference_batch = [['The dog bit the man.', 'The dog had bit the man.'], \n",
        "                   ['It was not unexpected.', 'No one was surprised.'],\n",
        "                   ['The man bit him first.', 'The man had bitten the dog.']]\n",
        "sys_batch = ['The dog bit the man.', \"It wasn't surprising.\", 'The man had just bitten him.']\n",
        "metric.add_batch(predictions=sys_batch, references=reference_batch)\n",
        "\n",
        "\n",
        "score = metric.compute()\n",
        "print(score)"
      ],
      "metadata": {
        "id": "FYf9YCTtnK4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METEOR"
      ],
      "metadata": {
        "id": "eiPuWEKHnlLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "# Evaluationsmetrik laden\n",
        "metric = load_metric('meteor')\n",
        "\n",
        "# Die nachstehende Zeile (wenn ohne \"#\" ausgeführt, beschreibt die Software-Bibliothek)\n",
        "#print(metric)\n",
        "\n",
        "reference_batch = [['The dog bit the man.', 'The dog had bit the man.'],\n",
        "                   ['It was not unexpected.', 'No one was surprised.'],\n",
        "                   ['The man bit him first.', 'The man had bitten the dog.']]\n",
        "sys_batch = ['The dog bit the man.', \"It wasn't surprising.\", 'The man had just bitten him.']\n",
        "metric.add_batch(predictions=sys_batch, references=reference_batch)\n",
        "\n",
        "\n",
        "score = metric.compute()\n",
        "print(score)"
      ],
      "metadata": {
        "id": "YofEBA4HuKAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TER"
      ],
      "metadata": {
        "id": "MLy3f1agvnRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "# Evaluationsmetrik laden\n",
        "metric = load_metric('ter')\n",
        "\n",
        "# Die nachstehende Zeile (wenn ohne \"#\" ausgeführt, beschreibt die Software-Bibliothek)\n",
        "#print(metric)\n",
        "\n",
        "reference_batch = [['The dog bit the man.', 'The dog had bit the man.'],\n",
        "                   ['It was not unexpected.', 'No one was surprised.'],\n",
        "                   ['The man bit him first.', 'The man had bitten the dog.']]\n",
        "sys_batch = ['The dog bit the man.', \"It wasn't surprising.\", 'The man had just bitten him.']\n",
        "metric.add_batch(predictions=sys_batch, references=reference_batch)\n",
        "\n",
        "\n",
        "score = metric.compute()\n",
        "print(score)"
      ],
      "metadata": {
        "id": "iIU06lyKvsWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dateien hochladen\n",
        "\n",
        "Am einfachsten geht das, wenn Sie Colab mit Google Drive verbinden. "
      ],
      "metadata": {
        "id": "hq971To2l51M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verbindung zu Google Drive herstellen \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VToh43i_l9Ky",
        "outputId": "d728515a-047d-48eb-8084-01597ce45a0b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In den richtigen Ordner wechseln\n",
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FIQUsQ7ti5o",
        "outputId": "88901cdf-ca0f-430d-acac-2033fda962a7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sicherstellen, dass Sie im richtigen Ordner sind indem Sie die Ordner und Dateien im Ordner ausgeben lassen \n",
        "%ls"
      ],
      "metadata": {
        "id": "JILZ1JWsty8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Richtigen Dateinamen hier eintragen statt z. B. \"references.txt\"\n",
        "references = open(\"references.txt\").read()\n",
        "translation = open(\"translated.txt\").read()\n",
        "\n",
        "print(\"References: \", references)\n",
        "print(\"Translation: \", translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y009bkcTydBp",
        "outputId": "027173bf-e5bf-4f74-b9bf-00d4f4bd0e46"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "References:  The dog bit the man. It was not unexpected. \n",
            "The man had bitten the dog. \n",
            "Translation:  The dog bit the man. It wasn't surprising.\n",
            "The man had just bitten him.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate BLEU like above but on a text file:"
      ],
      "metadata": {
        "id": "uETvtyiCzuB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Evaluationsmetrik laden\n",
        "metric = load_metric('meteor')\n",
        "\n",
        "# Die nachstehende Zeile (wenn ohne \"#\" ausgeführt, beschreibt die Software-Bibliothek)\n",
        "#print(metric)\n",
        "\n",
        "#Der Text in der Datei muss noch in einzelne Sätze unterteilt werden: \n",
        "translation_tokenized = sent_tokenize(translation)\n",
        "references_tokenized = [[sent] for sent in sent_tokenize(references)]\n",
        "\n",
        "print(translation_tokenized)\n",
        "print(references_tokenized)\n",
        "\n",
        "metric.add_batch(predictions=translation_tokenized, references=references_tokenized)\n",
        "\n",
        "\n",
        "score = metric.compute()\n",
        "print(score)"
      ],
      "metadata": {
        "id": "B-vWCVKczqit"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}